{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV to SQLite converter\n",
    "We used this python script to convert the providers.csv to an sqlite database, when we upgrade from the csv to an actual api implementation for the data this can be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your CSV file\n",
    "csv_file_path = './providers.csv'\n",
    "sqlite_db_path = '../db/providers.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for CSV reading\n",
    "CSV_HEADER_OFFSET = 2  # skip first 2 rows\n",
    "cursor = 0  # Adjust as needed\n",
    "limit = None  # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file_path, skiprows=CSV_HEADER_OFFSET + cursor, nrows=limit, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_int(value):\n",
    "    try:\n",
    "        return int(''.join(filter(str.isdigit, str(value)))) if pd.notnull(value) else None\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def parse_float(value):\n",
    "    try:\n",
    "        cleaned_value = ''.join(filter(lambda x: x.isdigit() or x == '.', str(value)))\n",
    "        # Handle cases with multiple periods (e.g., '3.53.9')\n",
    "        parts = cleaned_value.split('.')\n",
    "        if len(parts) > 2:\n",
    "            cleaned_value = parts[0] + '.' + ''.join(parts[1:])\n",
    "        return float(cleaned_value) if pd.notnull(value) else None\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def parse_bool(value):\n",
    "    return value.lower() == 'true' if pd.notnull(value) else None\n",
    "\n",
    "# \n",
    "def parse_storage(storage_str):\n",
    "    \"\"\"\n",
    "    Parse storage string and return the total storage in GB.\n",
    "    \"\"\"\n",
    "    if pd.isnull(storage_str):\n",
    "        return None\n",
    "    \n",
    "    # Handle the case with multiplications\n",
    "    pattern = re.compile(r'(\\d+)[xX]\\s*(\\d+\\.?\\d*)\\s*(TB|GB)')\n",
    "    match = pattern.search(storage_str)\n",
    "    \n",
    "    if match:\n",
    "        quantity = int(match.group(1))\n",
    "        size = float(match.group(2))\n",
    "        unit = match.group(3)\n",
    "        \n",
    "        if unit.upper() == 'TB':\n",
    "            size *= 1024  # Convert TB to GB\n",
    "        \n",
    "        return int(quantity * size)\n",
    "    \n",
    "    # Handle the case without multiplications\n",
    "    pattern = re.compile(r'(\\d+\\.?\\d*)\\s*(TB|GB)')\n",
    "    match = pattern.search(storage_str)\n",
    "    \n",
    "    if match:\n",
    "        size = float(match.group(1))\n",
    "        unit = match.group(2)\n",
    "        \n",
    "        if unit.upper() == 'TB':\n",
    "            size *= 1024  # Convert TB to GB\n",
    "        \n",
    "        return int(size)\n",
    "    \n",
    "    # If no pattern matches, return None\n",
    "    return None\n",
    "\n",
    "def parse_ghz(value):\n",
    "    if pd.isnull(value):\n",
    "        return None\n",
    "    \n",
    "    value = str(value)\n",
    "    \n",
    "    if '/' in value:\n",
    "        parts = value.split('/')\n",
    "        if len(parts) > 1 and parts[1].strip():\n",
    "            value = parts[1].strip()\n",
    "        else:\n",
    "            value = parts[0].strip()\n",
    "    \n",
    "    cleaned_value = ''.join(filter(lambda x: x.isdigit() or x == '.', value))\n",
    "    \n",
    "    try:\n",
    "        return float(cleaned_value)\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def parse_cores(value):\n",
    "    if pd.isnull(value):\n",
    "        return None\n",
    "    \n",
    "    value = str(value).strip()\n",
    "    \n",
    "    # Handle ranges like \"4-8\", \"4 - 8\", \"12-32\", \"12 - 32 Cores\"\n",
    "    range_pattern = re.compile(r'(\\d+)\\s*-\\s*(\\d+)')\n",
    "    match = range_pattern.search(value)\n",
    "    \n",
    "    if match:\n",
    "        return int(match.group(2))\n",
    "    \n",
    "    # Handle single values like \"8\", \"16\"\n",
    "    single_pattern = re.compile(r'(\\d+)')\n",
    "    match = single_pattern.match(value)\n",
    "    \n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    # If no pattern matches, return None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_row(row):\n",
    "    if pd.isnull(row.iloc[1]):\n",
    "        return None\n",
    "    return {\n",
    "        'providerName': row.iloc[1],\n",
    "        'productName': row.iloc[2],\n",
    "        'country': row.iloc[3],\n",
    "        'location': row.iloc[4],\n",
    "        'cpuCores': parse_cores(row.iloc[6]),\n",
    "        'cpuThreads': parse_int(row.iloc[8]),\n",
    "        'cpuGHZ': parse_ghz(row.iloc[9]),\n",
    "        'hasSGX': parse_bool(row.iloc[10]),\n",
    "        'ram': parse_int(row.iloc[41]),\n",
    "        'numberDrives': parse_int(row.iloc[43]),\n",
    "        'avgSizeDrive': parse_int(row.iloc[44]),\n",
    "        'storageTotal': parse_storage(row.iloc[62]),\n",
    "        'gpuType': row.iloc[63],\n",
    "        'gpuMemory': f\"{row.iloc[64]}_{row.iloc[65]}\",\n",
    "        'bandwidthNetwork': parse_int(row.iloc[67]),\n",
    "        'network': parse_int(row.iloc[68]),\n",
    "        'priceHour': parse_float(row.iloc[74]),\n",
    "        'priceMonth': parse_float(row.iloc[77]),\n",
    "        'priceSale': parse_float(row.iloc[78]),\n",
    "        'availability': row.iloc[79],\n",
    "        'source': row.iloc[80],\n",
    "        'unit': row.iloc[82],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformation to each row\n",
    "transformed_data = df.apply(transform_row, axis=1).dropna().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of dictionaries to a DataFrame\n",
    "transformed_df = pd.DataFrame(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the directory for the database exists\n",
    "import os\n",
    "os.makedirs(os.path.dirname(sqlite_db_path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "Incorrect number of bindings supplied. The current statement uses 21, and there are 22 supplied.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Insert the DataFrame into the SQLite table\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m transformed_df\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 34\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;43m        INSERT INTO providers (\u001b[39;49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;43m            providerName, productName, country, location, cpuCores, cpuThreads, cpuGHZ, hasSGX, ram, numberDrives, avgSizeDrive, storageTotal, gpuType, gpuMemory, bandwidthNetwork, network, priceHour, priceMonth, availability, source, unit\u001b[39;49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;43m        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\u001b[39;49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m conn\u001b[38;5;241m.\u001b[39mcommit()\n",
      "\u001b[0;31mProgrammingError\u001b[0m: Incorrect number of bindings supplied. The current statement uses 21, and there are 22 supplied."
     ]
    }
   ],
   "source": [
    "# Write the transformed data to a SQLite database with an auto-incrementing id column\n",
    "with sqlite3.connect(sqlite_db_path) as conn:\n",
    "    cursor = conn.cursor()\n",
    "    # Create table with an auto-incrementing id column\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS providers (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            providerName TEXT,\n",
    "            productName TEXT,\n",
    "            country TEXT,\n",
    "            location TEXT,\n",
    "            cpuCores INTEGER,\n",
    "            cpuThreads INTEGER,\n",
    "            cpuGHZ REAL,\n",
    "            hasSGX BOOLEAN,\n",
    "            ram INTEGER,\n",
    "            numberDrives INTEGER,\n",
    "            avgSizeDrive INTEGER,\n",
    "            storageTotal INTEGER,\n",
    "            gpuType TEXT,\n",
    "            gpuMemory TEXT,\n",
    "            bandwidthNetwork INTEGER,\n",
    "            network INTEGER,\n",
    "            priceHour REAL,\n",
    "            priceMonth REAL,\n",
    "            availability TEXT,\n",
    "            source TEXT,\n",
    "            unit TEXT\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "    # Insert the DataFrame into the SQLite table\n",
    "    for row in transformed_df.itertuples(index=False, name=None):\n",
    "        cursor.execute('''\n",
    "            INSERT INTO providers (\n",
    "                providerName, productName, country, location, cpuCores, cpuThreads, cpuGHZ, hasSGX, ram, numberDrives, avgSizeDrive, storageTotal, gpuType, gpuMemory, bandwidthNetwork, network, priceHour, priceMonth, availability, source, unit\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', row)\n",
    "    \n",
    "    conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-gloria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
